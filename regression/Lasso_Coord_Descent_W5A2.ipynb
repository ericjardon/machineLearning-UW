{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: LASSO (coordinate descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement our own LASSO solver via coordinate descent.\n",
    "For this goal, we:\n",
    "* write a function to normalize features\n",
    "* implement coordinate descent for LASSO\n",
    "* explore effects of L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = tc.SFrame('../data/home_data.sframe/')\n",
    "\n",
    "# Convert 'floors' from string into integer\n",
    "sales['floors'] = sales['floors'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Any \"feature engineering\" (like creating new features or adjusting existing ones) should be done directly using the SFrames as seen in the first notebook of Week 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing functions from previous notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Week 2, we take `get_num_data()` in order to we convert SFrames into 2D Numpy arrays for matrix manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Receives an SFrame, a list of input feature names, and the name of target feature.\n",
    "    Returns a 2d numpy array of the data matrix, and the np array of the target (outcome) vector\"\"\"\n",
    "def get_numpy_data(data_sframe, features, target):\n",
    "    # Add constant column for the Intercept\n",
    "    data_sframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    \n",
    "    # Subselect the features from the original, including constant\n",
    "    features_sframe = data_sframe[features]\n",
    "    \n",
    "    # Convert into a numpy matrix\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    \n",
    "    # Subselect the target vector and convert into numpy array\n",
    "    output_sarray = data_sframe[target]\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    \n",
    "    return (feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, copy and paste the `predict_output()` function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Performs the dot product between features matrix and weight vector.\n",
    "    Returns a numpy array of predicted values.\"\"\"\n",
    "def predict_output(feature_matrix, weights):   \n",
    "    # Assume feature_matrix is a numpy matrix with features as columns,\n",
    "    # Weights is a numpy array of a model's coefficients.\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing features\n",
    "In the house dataset, features vary wildly in their relative magnitude. <br>\n",
    "For instance, `sqft_living` is very large overall compared to `bedrooms`. <br>\n",
    "As a result, the weight for `sqft_living` would be much smaller than the weight for `bedrooms`. This is problematic because **\"small\" weights are dropped first as `l1_penalty` goes up**. \n",
    "\n",
    "To give equal considerations for all features, we need to **normalize features**: we divide each feature by its 2-norm so that the transformed feature has norm 1.\n",
    "\n",
    "We can do this normalization easily with Numpy: let us first consider a small matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy provides a shorthand for computing 2-norms of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5. 13. 17.]\n"
     ]
    }
   ],
   "source": [
    "# Init a numpy matrix of 2x3\n",
    "X = np.array([[3.,5.,8.],[4.,12.,15.]])\n",
    "\n",
    "norms = np.linalg.norm(X, axis=0) # computes norm of each column: [norm(X[:,0]), norm(X[:,1]), norm(X[:,2])]\n",
    "print(norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To normalize, apply element-wise division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6        0.38461538 0.47058824]\n",
      " [0.8        0.92307692 0.88235294]]\n"
     ]
    }
   ],
   "source": [
    "print(X / norms) # applies division element-wise [X[:,0]/norm(X[:,0]), X[:,1]/norm(X[:,1]), X[:,2]/norm(X[:,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a short function called `normalize_features(feature_matrix)`, which normalizes the columns of a given feature matrix. <br>\n",
    "The function returns a pair `(normalized_features, norms)`, where the second item contains the norms of the original features. <br>\n",
    "These norms are used to normalize the test data just as we normalized the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Receives a numpy matrix (i.e. a 2D numpy array), \n",
    "    returns a numpy matrix with normalized feature columns, and the numpy array of 2-norms of each column\"\"\"\n",
    "def normalize_features(feature_matrix):\n",
    "    norms = np.linalg.norm(feature_matrix, axis=0)\n",
    "    normalized_features = feature_matrix / norms\n",
    "    \n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6 0.6 0.6]\n",
      " [0.8 0.8 0.8]]\n",
      "[ 5. 10. 15.]\n"
     ]
    }
   ],
   "source": [
    "features, norms = normalize_features(np.array([[3.,6.,9.],[4.,8.,12.]]))\n",
    "print (features)\n",
    "# should print\n",
    "# [[ 0.6  0.6  0.6]\n",
    "#  [ 0.8  0.8  0.8]]\n",
    "print (norms)\n",
    "# should print\n",
    "# [5.  10.  15.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate Descent Implementation (normalized features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Coordinate Descent?\n",
    "\n",
    "We seek to obtain a sparse set of weights by minimizing the LASSO Cost function (Objective), given by\n",
    "`Cost = RSS + L1_norm` <br>\n",
    "Specifically,\n",
    "```\n",
    "SUM[(prediction - output)^2] + lambda*( |w[1]| + ... + |w[k]|).\n",
    "```\n",
    "(By convention, we do not include `w[0]` in the L1 penalty term, since we never want to push the intercept to zero.)\n",
    "\n",
    "We cannot use gradient descent because the absolute value sign makes the cost function non-differentiable (unless we used subgradient descent). <br>\n",
    "Instead, we will use **coordinate descent**. At every iteration, we will fix all weights except the `i`-th weight, and find the value of the `i`-th weight that minimizes the Cost using partial derivatives. <br>\n",
    "\n",
    "To compute the Objective's partial derivative with respecto to the `i`-th weight, all weights other than `w[i]` are held to be constant.\n",
    "\n",
    "In summary, we optimize one `w[i]` at a time, circling through the weights multiple times. \n",
    "  1. Pick a coordinate `i`\n",
    "  2. Compute `w[i]` that minimizes the cost function `SUM[ (prediction - output)^2 ] + lambda*( |w[1]| + ... + |w[k]|)`\n",
    "  3. Repeat Steps 1 and 2 for all coordinates, until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our implementation\n",
    "For this notebook, we use **cyclical coordinate descent with normalized features**. \n",
    "- We cycle through coordinates in order through the range `0:(D-1)`, assuming the features were normalized as discussed above. <br>\n",
    "- The formula for optimizing each coordinate is as follows:\n",
    "```\n",
    "       ┌ (ro[i] + lambda/2)     if ro[i] < -lambda/2\n",
    "w[i] = ├ 0                      if -lambda/2 <= ro[i] <= lambda/2\n",
    "       └ (ro[i] - lambda/2)     if ro[i] > lambda/2\n",
    "```\n",
    "    where ro is given by:\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ].\n",
    "```\n",
    "where the sum traverses all the items of the resulting vector in brackets.\n",
    "\n",
    "Note that for the intercept the update is simply:\n",
    "```\n",
    "w[0] = ro[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The role of the L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider a simple model with 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "simple_feature_matrix, output = get_numpy_data(sales, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "simple_feature_matrix, norms = normalize_features(simple_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign some random set of initial weights\n",
    "weights = np.array([1., 4., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predicted values\n",
    "predictions = predict_output(simple_feature_matrix, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the values of `ro[i]`\n",
    "Compute the values of `ro[i]` of each feature in the simple model, using the formula:\n",
    "```\n",
    "ro[i] = SUM[ [feature_i]*(output - prediction + w[i]*[feature_i]) ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[79400300.03492916, 87939470.77299108, 80966698.67596565]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = len(simple_feature_matrix[0])\n",
    "ro = list()\n",
    "\n",
    "for i in range(D):\n",
    "    feature_col = simple_feature_matrix[:,i]\n",
    "    \n",
    "    temp = feature_col * (output - predictions + weights[i]*feature_col)  # returns an array\n",
    "    \n",
    "    ro_i = temp.sum()\n",
    "    ro.append(ro_i)\n",
    "\n",
    "ro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Whenever `ro[i]` falls between `-l1_penalty/2` and `l1_penalty/2` (inclusive), the weight `w[i]` is sent to zero. \n",
    "<br>\n",
    "Now suppose we were to take one step of coordinate descent on either feature 1 or feature 2. \n",
    "<br>\n",
    "What range of values of `l1_penalty` **would** set `w[2]` to zero but **not** `w[1]`?\n",
    "<br>\n",
    "`A = (ro[2]*2, (ro[1]-1)*2)`, rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.619334e+08 , 1.758789e+08\n",
      "w[2] to zero A\n",
      "w[2] to zero B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "175878941.54598215"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endA = ro[2]*2 # min value, shoud be equal to ro[2]*2\n",
    "endB = (ro[1]-1)*2 # max value, ro[1] should still be larger\n",
    "print(\"{:e}\".format(endA),\",\" , \"{:e}\".format(endB))\n",
    "\n",
    "if ro[1] <= endA/2.0: print(\"w[1] to zero A\")\n",
    "if ro[2] <= endA/2.0: print(\"w[2] to zero A\")\n",
    "    \n",
    "if ro[1] <= endB/2.0: print(\"w[1] to zero B\")\n",
    "if ro[2] <= endB/2.0: print(\"w[2] to zero B\")\n",
    "\n",
    "ro[2]*2\n",
    "ro[1]*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What range of values of `l1_penalty` would set **both** `w[1]` and `w[2]` to zero, if we were to take a step in that coordinate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w[1] to zero\n",
      "w[2] to zero\n"
     ]
    }
   ],
   "source": [
    "if ro[1] < 175878941.546/2: print(\"w[1] to zero\")\n",
    "if ro[2] < 175878941.546/2: print(\"w[2] to zero\")\n",
    "# 175878941.546 and up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus, we can say that `ro[i]` quantifies the significance of the i-th feature: the larger `ro[i]` is, the more likely the i-th feature is to be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Coordinate Descent Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement coordinate descent that minimizes the cost function over a single feature i. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Receives a feature matrix, output vector, current weights, l1 penalty, and index of feature to optimize over. \n",
    "   Computes and returns the new weight for feature i (ith weight).\"\"\"\n",
    "def lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty):\n",
    "    # compute prediction\n",
    "    predictions = predict_output(feature_matrix, weights)\n",
    "    \n",
    "    # ro is computed based on the prediction made without using the i-th weight\n",
    "    feature_col = feature_matrix[:,i] \n",
    "    temp = feature_col * (output - predictions + weights[i]*feature_col)\n",
    "    ro_i = temp.sum()\n",
    "\n",
    "    if i == 0: \n",
    "        # intercept -- do not regularize\n",
    "        new_weight_i = ro_i \n",
    "    elif ro_i < -l1_penalty/2.:\n",
    "        new_weight_i = ro_i + l1_penalty/2.\n",
    "    elif ro_i > l1_penalty/2.:\n",
    "        new_weight_i = ro_i - l1_penalty/2.\n",
    "    else:\n",
    "        new_weight_i = 0.\n",
    "    \n",
    "    return new_weight_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4255588466910251\n"
     ]
    }
   ],
   "source": [
    "# should print 0.425558846691\n",
    "import math\n",
    "print(lasso_coordinate_descent_step(1, np.array([[3./math.sqrt(13),1./math.sqrt(10)],[2./math.sqrt(13),3./math.sqrt(10)]]), \n",
    "                                    np.array([1., 1.]), np.array([1., 4.]), 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cyclical coordinate descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previous helper function, we can implement cyclical coordinate descent where we optimize coordinates 0, 1, ..., up to (D-1) in order and repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each iteration:\n",
    "1. As you loop over features in order and perform coordinate descent, measure how much each coordinate changes.\n",
    "2. After the loop, if the maximum change across all coordinates is falls below the tolerance, stop. Otherwise, go back to step 1.\n",
    "\n",
    "Finally, return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "\n",
    "\"\"\"Performs cyclical coordinate descent given a feature matrix NxD, target output vector, initial weights vector,\n",
    "    l1 penalty (lambda), and a stopping tolerance.\n",
    "    Returns the array of optimal weights\"\"\"\n",
    "def lasso_cyclical_coordinate_descent(feature_matrix, output, initial_weights, l1_penalty, tolerance):\n",
    "    D = len(initial_weights)\n",
    "    weights = np.copy(initial_weights)\n",
    "    converged = False\n",
    "    it = 0\n",
    "    \n",
    "    while (not converged):\n",
    "        it+=1\n",
    "        # Reset iteration's change\n",
    "        max_change=0\n",
    "        # Update all weights\n",
    "        for i in range(D):\n",
    "            old_w_i = weights[i]\n",
    "            weights[i] = lasso_coordinate_descent_step(i, feature_matrix, output, weights, l1_penalty)\n",
    "            change = abs(old_w_i - weights[i])\n",
    "            max_change = max(max_change, change)  # keep track of max change in one pass\n",
    "        \n",
    "        converged = max_change < tolerance\n",
    "    \n",
    "    print(f\"After {it} iterations\")\n",
    "    print(weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following parameters, learn the weights on the sales dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living', 'bedrooms']\n",
    "my_output = 'price'\n",
    "initial_weights = np.zeros(3)\n",
    "l1_penalty = 1e7\n",
    "tolerance = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of the feature matrix, `normalized_simple_feature_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_feature_matrix, output = get_numpy_data(sales, simple_features, my_output)\n",
    " # normalize features\n",
    "normalized_simple_feature_matrix, simple_norms = normalize_features(simple_feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run our LASSO CD implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 93 iterations\n",
      "[21624998.36636292 63157246.78545421        0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = lasso_cyclical_coordinate_descent(normalized_simple_feature_matrix, output,\n",
    "                                            initial_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What is the RSS of the learned model on the normalized dataset? (Hint: use the normalized feature matrix when you make predictions.)\n",
    "2. Which features had weight zero at convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS: 1.630492e+15\n"
     ]
    }
   ],
   "source": [
    "# Compute RSS of the model on the normalized dataset\n",
    "simple_predictions = predict_output(normalized_simple_feature_matrix, weights)\n",
    "residuals = output - simple_predictions\n",
    "rss = (residuals**2).sum()\n",
    "rss_print = \"{:e}\".format(rss)\n",
    "print(f\"RSS: {rss_print}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LASSO fit with more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the sales dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = ['bedrooms',\n",
    "                'bathrooms',\n",
    "                'sqft_living',\n",
    "                'sqft_lot',\n",
    "                'floors',\n",
    "                'waterfront', \n",
    "                'view', \n",
    "                'condition', \n",
    "                'grade',\n",
    "                'sqft_above',\n",
    "                'sqft_basement',\n",
    "                'yr_built', \n",
    "                'yr_renovated']\n",
    "len(all_features) + 1  # including the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a normalized feature matrix from the TRAINING data with these features.  (Make you store the norms for the normalization, since we'll use them later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix, train_output = get_numpy_data(train_data, all_features, 'price')\n",
    "# Normalize features\n",
    "normalized_train_matrix, train_norms = normalize_features(train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, learn the weights with `l1_penalty=1e7`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e7`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = np.zeros(14)\n",
    "tolerance=1\n",
    "l1_penalty=1e7\n",
    "\n",
    "weights1e7 = lasso_cyclical_coordinate_descent(normalized_train_matrix, train_output,\n",
    "                                            init_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?\n",
    "<br> A:\n",
    "- intercept\n",
    "- sqft_living\n",
    "- waterfront\n",
    "- view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 14\n",
      "intercept : 24429600.609333135\n",
      "sqft_living : 48389174.35227978\n",
      "waterfront : 3317511.162719814\n",
      "view : 7329961.984896399\n"
     ]
    }
   ],
   "source": [
    "col_names = ['intercept'] + all_features\n",
    "print(\"Features:\", len(col_names))\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    if weights1e7[i] != 0.:\n",
    "        print(f\"{col_names[i]} : {weights1e7[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, learn the weights with `l1_penalty=1e8`, on the training data. Initialize weights to all zeros, and set the `tolerance=1`.  Call resulting weights `weights1e8`, you will need them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = np.zeros(14)\n",
    "tolerance=1\n",
    "l1_penalty=1e8\n",
    "\n",
    "weights1e8 = lasso_cyclical_coordinate_descent(normalized_train_matrix, train_output,\n",
    "                                            init_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?\n",
    "<br>A:\n",
    "- intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 14\n",
      "intercept : 71114625.75280938\n"
     ]
    }
   ],
   "source": [
    "col_names = ['intercept'] + all_features\n",
    "print(\"Features:\", len(col_names))\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    if weights1e8[i] != 0.:\n",
    "        print(f\"{col_names[i]} : {weights1e8[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, learn the weights with `l1_penalty=1e4`, on the training data. Initialize weights to all zeros, and set the `tolerance=5e5`.  Call resulting weights `weights1e4`, you will need them later.  (This case will take quite a bit longer to converge than the others above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_weights = np.zeros(14)\n",
    "tolerance=5e5\n",
    "l1_penalty=1e4\n",
    "\n",
    "weights1e4 = lasso_cyclical_coordinate_descent(normalized_train_matrix, train_output,\n",
    "                                            init_weights, l1_penalty, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "What features had non-zero weight in this case?\n",
    "<br>A: all of them (14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 14\n",
      "intercept : 77779073.91265233\n",
      "bedrooms : -22884012.250233646\n",
      "bathrooms : 15348487.080899928\n",
      "sqft_living : 92166869.69883084\n",
      "sqft_lot : -2139328.082427805\n",
      "floors : -8818455.544094978\n",
      "waterfront : 6494209.733106552\n",
      "view : 7065162.050531973\n",
      "condition : 4119079.210067598\n",
      "grade : 18436483.52618777\n",
      "sqft_above : -14566678.545143452\n",
      "sqft_basement : -5528348.751794279\n",
      "yr_built : -83591746.20730534\n",
      "yr_renovated : 2784276.4601285765\n"
     ]
    }
   ],
   "source": [
    "col_names = ['intercept'] + all_features\n",
    "print(\"Features:\", len(col_names))\n",
    "\n",
    "for i in range(len(col_names)):\n",
    "    if weights1e4[i] != 0.:\n",
    "        print(f\"{col_names[i]} : {weights1e4[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling learned weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our weights were computed on a normalized dataset.\n",
    "To use these weights on a test set, we would have to normalize the test data too.\n",
    "\n",
    "we can alternatively **rescale the learned weights** to include the normalization, **so we don't have to worry about normalizing any dataset anymore**.\n",
    "\n",
    "We will scale our resulting weights so that we can make predictions with *original* features:\n",
    "Computing the weights for the original features by performing element-wise division, i.e.\n",
    "```\n",
    "weights_normalized = weights / norms\n",
    "```\n",
    "Now, we can apply `weights_normalized` to the test data, without having to noramlize it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a normalized version of each of the weights learned above. (`weights1e4`, `weights1e7`, `weights1e8`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_train_matrix, train_norms = normalize_features(train_matrix)\n",
    "\n",
    "weights1e4_n = weights1e4 / train_norms\n",
    "weights1e7_n = weights1e7 / train_norms\n",
    "weights1e8_n = weights1e8 / train_norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating each of the learned models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the three models on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, all_features, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS of each of the three normalized weights on the (unnormalized) `test_feature_matrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1e4 RSS: 2.277810e+14\n"
     ]
    }
   ],
   "source": [
    "# Model with l1 = 1e4 \n",
    "predictions = predict_output(test_feature_matrix, weights1e4_n)\n",
    "residuals = test_output - predictions\n",
    "rss = (residuals**2).sum()\n",
    "print_rss = \"{:e}\".format(rss)\n",
    "print(f\"Model 1e4 RSS: {print_rss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1e7 RSS: 2.759621e+14\n"
     ]
    }
   ],
   "source": [
    "# Model with l1 = 1e7\n",
    "predictions = predict_output(test_feature_matrix, weights1e7_n)\n",
    "residuals = test_output - predictions\n",
    "rss = (residuals**2).sum()\n",
    "print_rss = \"{:e}\".format(rss)\n",
    "print(f\"Model 1e7 RSS: {print_rss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1e8 RSS: 5.371662e+14\n"
     ]
    }
   ],
   "source": [
    "# Model with l1 = 1e8\n",
    "predictions = predict_output(test_feature_matrix, weights1e8_n)\n",
    "residuals = test_output - predictions\n",
    "rss = (residuals**2).sum()\n",
    "print_rss = \"{:e}\".format(rss)\n",
    "print(f\"Model 1e8 RSS: {print_rss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "\n",
    "Which model performed best on the test data?\n",
    "<br>\n",
    "A: Model 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
